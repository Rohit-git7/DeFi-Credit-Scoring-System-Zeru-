{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NweZTb1alQfY",
        "outputId": "f2a49ec3-3842-4e45-d296-f7c6482ba444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading transaction data...\n",
            "Available columns: ['_id', 'userWallet', 'network', 'protocol', 'txHash', 'logId', 'timestamp', 'blockNumber', 'action', 'actionData', '__v', 'createdAt', 'updatedAt']\n",
            "Sample record structure detected\n",
            "Extracting nested actionData fields...\n",
            "Updated columns after extraction: ['_id', 'userWallet', 'network', 'protocol', 'txHash', 'logId', 'timestamp', 'blockNumber', 'action', '__v', 'createdAt', 'updatedAt', 'type', 'amount', 'assetSymbol', 'assetPriceUSD', 'poolId', 'userId', 'toId', 'borrowRateMode', 'borrowRate', 'variableTokenDebt', 'stableTokenDebt', 'callerId', 'useATokens', 'repayerId', 'liquidatorId', 'collateralAmount', 'collateralAssetPriceUSD', 'principalAmount', 'borrowAssetPriceUSD', 'collateralReserveId', 'collateralReserveSymbol', 'principalReserveId', 'principalReserveSymbol']\n",
            "Mapped userWallet -> wallet\n",
            "Mapped assetSymbol -> asset\n",
            "Mapped amount -> amount\n",
            "Mapped action -> action\n",
            "Mapped timestamp -> timestamp\n",
            "Converting amounts from raw token units...\n",
            "Loaded 99752 valid transactions (filtered from 100000)\n",
            "Unique wallets: 3497\n",
            "Actions: ['deposit' 'redeemunderlying' 'borrow' 'repay']\n",
            "Assets: ['USDC' 'WMATIC' 'DAI' 'WBTC' 'WETH' 'USDT' 'WPOL' 'AAVE']\n",
            "Amount range: $0.00 - $12,730,000,000,000,000,000.00\n",
            "Loaded 99752 transactions for 3497 unique wallets\n",
            "Engineering features...\n",
            "Calculating component scores...\n",
            "Calculating final credit scores...\n",
            "Generating report...\n",
            "Results saved to wallet_credit_scores.csv\n",
            "\n",
            "=== CREDIT SCORING REPORT ===\n",
            "Total Wallets Analyzed: 3497\n",
            "Average Credit Score: 624.3\n",
            "\n",
            "Score Distribution:\n",
            "  Fair (Elevated Risk): 2396 wallets\n",
            "  Poor (High Risk): 476 wallets\n",
            "  Good (Moderate Risk): 472 wallets\n",
            "  Very Poor (Very High Risk): 146 wallets\n",
            "  Excellent (Low Risk): 7 wallets\n",
            "\n",
            "Component Score Averages:\n",
            "  reliability_score: 0.451\n",
            "  utilization_score: 0.927\n",
            "  longevity_score: 0.148\n",
            "  diversity_score: 0.512\n",
            "  liquidation_risk_score: 1.000\n",
            "  bot_behavior_score: 0.990\n",
            "  volume_consistency_score: 0.076\n",
            "\n",
            "Top 5 Wallets:\n",
            "  0x005ce3720edd52ef800ed68bfe29114a7d86e623: 836.5 (Excellent (Low Risk))\n",
            "  0x01f9605611b8490c0c70f40979c61b21dc1b6f3e: 829.6 (Excellent (Low Risk))\n",
            "  0x05250b39a5c97c289c79ce2c83f3af8dd60aa438: 825.9 (Excellent (Low Risk))\n",
            "  0x0465130e29be525707f2e38726e1465d632efbbf: 811.8 (Excellent (Low Risk))\n",
            "  0x00e2362abcebe7833138bd460000ba5d4f6ee1e6: 807.2 (Excellent (Low Risk))\n",
            "\n",
            "Bottom 5 Wallets:\n",
            "  0x02ca884e10a36b822c996a3339bdd21417a4d092: 369.7 (Very Poor (Very High Risk))\n",
            "  0x03a673e4a53120a0f6f57e49b202f38553917136: 374.2 (Very Poor (Very High Risk))\n",
            "  0x039eda3933ce405c2ff54a93a7afa07c08030164: 375.6 (Very Poor (Very High Risk))\n",
            "  0x05be4b528e49d3315f2e98343b70197805809327: 379.2 (Very Poor (Very High Risk))\n",
            "  0x03572f17c8e8ac3d5e5f767bff74dca89f310225: 382.3 (Very Poor (Very High Risk))\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class DeFiCreditScorer:\n",
        "    def __init__(self):\n",
        "        self.feature_weights = {\n",
        "            'reliability_score': 0.25,      # Payment history and consistency\n",
        "            'utilization_score': 0.20,      # Debt-to-collateral ratios\n",
        "            'longevity_score': 0.15,        # Account age and activity duration\n",
        "            'diversity_score': 0.10,        # Asset and action diversity\n",
        "            'liquidation_risk_score': 0.15, # Liquidation history and risk\n",
        "            'bot_behavior_score': 0.10,     # Anti-bot detection\n",
        "            'volume_consistency_score': 0.05 # Transaction volume patterns\n",
        "        }\n",
        "\n",
        "    def load_data(self, json_file_path: str) -> pd.DataFrame:\n",
        "        \"\"\"Load and preprocess transaction data from JSON file\"\"\"\n",
        "        with open(json_file_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(data)\n",
        "\n",
        "        # Print available columns for debugging\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "        print(f\"Sample record structure detected\")\n",
        "\n",
        "        # Extract nested actionData fields\n",
        "        if 'actionData' in df.columns:\n",
        "            print(\"Extracting nested actionData fields...\")\n",
        "\n",
        "            # Extract actionData into separate columns\n",
        "            action_data_df = pd.json_normalize(df['actionData'])\n",
        "\n",
        "            # Combine with main dataframe\n",
        "            df = pd.concat([df.drop('actionData', axis=1), action_data_df], axis=1)\n",
        "\n",
        "            print(f\"Updated columns after extraction: {list(df.columns)}\")\n",
        "\n",
        "        # Map the specific fields from your data structure\n",
        "        field_mapping = {\n",
        "            'wallet': 'userWallet',  # userWallet -> wallet\n",
        "            'asset': 'assetSymbol',  # assetSymbol -> asset\n",
        "            'amount': 'amount',      # amount -> amount (already correct)\n",
        "            'action': 'action',      # action -> action (already correct)\n",
        "            'timestamp': 'timestamp' # timestamp -> timestamp (already correct)\n",
        "        }\n",
        "\n",
        "        # Apply field mapping\n",
        "        for standard_name, source_field in field_mapping.items():\n",
        "            if source_field in df.columns:\n",
        "                if standard_name != source_field:\n",
        "                    df[standard_name] = df[source_field]\n",
        "                print(f\"Mapped {source_field} -> {standard_name}\")\n",
        "            else:\n",
        "                print(f\"Warning: {source_field} not found in data\")\n",
        "\n",
        "        # Validate required fields exist\n",
        "        required_fields = ['wallet', 'action', 'asset', 'amount', 'timestamp']\n",
        "        missing_fields = [field for field in required_fields if field not in df.columns]\n",
        "\n",
        "        if missing_fields:\n",
        "            print(f\"Error: Missing required fields: {missing_fields}\")\n",
        "            print(\"Available fields:\", list(df.columns))\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Convert data types\n",
        "        try:\n",
        "            # Convert timestamp\n",
        "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert timestamp: {e}\")\n",
        "\n",
        "        # Convert amount to numeric (handle string amounts like \"2000000000\")\n",
        "        df['amount'] = pd.to_numeric(df['amount'], errors='coerce')\n",
        "\n",
        "        # Handle USDC decimals (USDC has 6 decimals, so divide by 1e6)\n",
        "        # Detect if amounts seem to be in raw token units\n",
        "        if df['amount'].median() > 1000000:  # Likely raw token units\n",
        "            print(\"Converting amounts from raw token units...\")\n",
        "            # Apply decimal conversion based on common token decimals\n",
        "            df['amount'] = df['amount'] / 1e6  # Assuming USDC-like tokens (6 decimals)\n",
        "\n",
        "        # Remove rows with invalid data\n",
        "        original_count = len(df)\n",
        "        df = df.dropna(subset=['wallet', 'action', 'timestamp', 'amount'])\n",
        "        df = df[df['amount'] > 0]  # Remove zero/negative amounts\n",
        "\n",
        "        print(f\"Loaded {len(df)} valid transactions (filtered from {original_count})\")\n",
        "        print(f\"Unique wallets: {df['wallet'].nunique()}\")\n",
        "        print(f\"Actions: {df['action'].unique()}\")\n",
        "        print(f\"Assets: {df['asset'].unique()}\")\n",
        "        print(f\"Amount range: ${df['amount'].min():.2f} - ${df['amount'].max():,.2f}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Engineer features for each wallet\"\"\"\n",
        "        wallet_features = []\n",
        "\n",
        "        for wallet in df['wallet'].unique():\n",
        "            wallet_data = df[df['wallet'] == wallet].copy()\n",
        "            wallet_data = wallet_data.sort_values('timestamp')\n",
        "\n",
        "            features = self._calculate_wallet_features(wallet_data)\n",
        "            features['wallet'] = wallet\n",
        "            wallet_features.append(features)\n",
        "\n",
        "        return pd.DataFrame(wallet_features)\n",
        "\n",
        "    def _calculate_wallet_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate comprehensive features for a single wallet\"\"\"\n",
        "        features = {}\n",
        "\n",
        "        # Basic transaction metrics\n",
        "        features.update(self._basic_transaction_features(wallet_data))\n",
        "\n",
        "        # Reliability and payment behavior\n",
        "        features.update(self._reliability_features(wallet_data))\n",
        "\n",
        "        # Utilization and risk management\n",
        "        features.update(self._utilization_features(wallet_data))\n",
        "\n",
        "        # Behavioral patterns\n",
        "        features.update(self._behavioral_features(wallet_data))\n",
        "\n",
        "        # Liquidation and risk indicators\n",
        "        features.update(self._liquidation_risk_features(wallet_data))\n",
        "\n",
        "        # Bot detection features\n",
        "        features.update(self._bot_detection_features(wallet_data))\n",
        "\n",
        "        return features\n",
        "\n",
        "    def _basic_transaction_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate basic transaction statistics\"\"\"\n",
        "        return {\n",
        "            'total_transactions': len(wallet_data),\n",
        "            'unique_assets': wallet_data['asset'].nunique(),\n",
        "            'unique_actions': wallet_data['action'].nunique(),\n",
        "            'total_volume': wallet_data['amount'].sum(),\n",
        "            'avg_transaction_size': wallet_data['amount'].mean(),\n",
        "            'account_age_days': (wallet_data['timestamp'].max() - wallet_data['timestamp'].min()).days + 1,\n",
        "            'transactions_per_day': len(wallet_data) / max(1, (wallet_data['timestamp'].max() - wallet_data['timestamp'].min()).days + 1)\n",
        "        }\n",
        "\n",
        "    def _reliability_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate reliability and payment behavior features\"\"\"\n",
        "        # Repayment behavior\n",
        "        borrows = wallet_data[wallet_data['action'] == 'borrow']\n",
        "        repays = wallet_data[wallet_data['action'] == 'repay']\n",
        "\n",
        "        borrow_volume = borrows['amount'].sum() if len(borrows) > 0 else 0\n",
        "        repay_volume = repays['amount'].sum() if len(repays) > 0 else 0\n",
        "\n",
        "        # Transaction frequency consistency\n",
        "        daily_txns = wallet_data.groupby(wallet_data['timestamp'].dt.date).size()\n",
        "        frequency_consistency = 1 - (daily_txns.std() / max(daily_txns.mean(), 1))\n",
        "\n",
        "        return {\n",
        "            'repayment_ratio': repay_volume / max(borrow_volume, 1),\n",
        "            'borrow_count': len(borrows),\n",
        "            'repay_count': len(repays),\n",
        "            'frequency_consistency': max(0, frequency_consistency),\n",
        "            'avg_days_between_transactions': self._calculate_avg_time_between_txns(wallet_data)\n",
        "        }\n",
        "\n",
        "    def _utilization_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate utilization and risk management features\"\"\"\n",
        "        deposits = wallet_data[wallet_data['action'] == 'deposit']\n",
        "        borrows = wallet_data[wallet_data['action'] == 'borrow']\n",
        "\n",
        "        total_deposits = deposits['amount'].sum() if len(deposits) > 0 else 0\n",
        "        total_borrows = borrows['amount'].sum() if len(borrows) > 0 else 0\n",
        "\n",
        "        # Calculate utilization ratio\n",
        "        utilization_ratio = total_borrows / max(total_deposits, 1)\n",
        "\n",
        "        # Healthy utilization is typically below 0.8 (80%)\n",
        "        healthy_utilization_score = max(0, 1 - max(0, utilization_ratio - 0.8) * 5)\n",
        "\n",
        "        return {\n",
        "            'total_deposits': total_deposits,\n",
        "            'total_borrows': total_borrows,\n",
        "            'utilization_ratio': utilization_ratio,\n",
        "            'healthy_utilization_score': healthy_utilization_score,\n",
        "            'deposit_count': len(deposits),\n",
        "            'deposit_to_borrow_ratio': len(deposits) / max(len(borrows), 1)\n",
        "        }\n",
        "\n",
        "    def _behavioral_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate behavioral pattern features\"\"\"\n",
        "        # Time-based patterns\n",
        "        wallet_data['hour'] = wallet_data['timestamp'].dt.hour\n",
        "        wallet_data['day_of_week'] = wallet_data['timestamp'].dt.dayofweek\n",
        "\n",
        "        # Diversity scores\n",
        "        asset_diversity = wallet_data['asset'].nunique() / max(len(wallet_data), 1)\n",
        "        action_diversity = wallet_data['action'].nunique() / 5  # 5 possible actions\n",
        "\n",
        "        # Transaction timing patterns\n",
        "        hour_std = wallet_data['hour'].std()\n",
        "        day_variety = wallet_data['day_of_week'].nunique()\n",
        "\n",
        "        return {\n",
        "            'asset_diversity_score': asset_diversity,\n",
        "            'action_diversity_score': action_diversity,\n",
        "            'hour_pattern_consistency': 1 - (hour_std / 12) if hour_std else 1,\n",
        "            'day_variety_score': day_variety / 7,\n",
        "            'weekend_activity_ratio': len(wallet_data[wallet_data['day_of_week'].isin([5, 6])]) / len(wallet_data)\n",
        "        }\n",
        "\n",
        "    def _liquidation_risk_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate liquidation and risk indicators\"\"\"\n",
        "        liquidations = wallet_data[wallet_data['action'] == 'liquidationcall']\n",
        "\n",
        "        # Recent activity weight (more recent = higher weight)\n",
        "        recent_cutoff = wallet_data['timestamp'].max() - timedelta(days=30)\n",
        "        recent_activity = wallet_data[wallet_data['timestamp'] >= recent_cutoff]\n",
        "        recent_activity_ratio = len(recent_activity) / len(wallet_data)\n",
        "\n",
        "        return {\n",
        "            'liquidation_count': len(liquidations),\n",
        "            'liquidation_volume': liquidations['amount'].sum() if len(liquidations) > 0 else 0,\n",
        "            'was_liquidated': 1 if len(liquidations) > 0 else 0,\n",
        "            'recent_activity_ratio': recent_activity_ratio,\n",
        "            'risk_score': min(1, len(liquidations) * 0.3)  # Each liquidation increases risk\n",
        "        }\n",
        "\n",
        "    def _bot_detection_features(self, wallet_data: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Calculate features to detect bot-like behavior\"\"\"\n",
        "        # Transaction amount patterns\n",
        "        amount_std = wallet_data['amount'].std()\n",
        "        amount_mean = wallet_data['amount'].mean()\n",
        "        amount_cv = amount_std / max(amount_mean, 1)  # Coefficient of variation\n",
        "\n",
        "        # Time interval patterns\n",
        "        time_diffs = wallet_data['timestamp'].diff().dropna()\n",
        "        time_intervals = time_diffs.dt.total_seconds()\n",
        "\n",
        "        # Round number bias (bots often use round numbers)\n",
        "        round_amounts = wallet_data['amount'].apply(lambda x: x == round(x, 0) if pd.notna(x) else False)\n",
        "        round_ratio = round_amounts.mean() if len(round_amounts) > 0 else 0\n",
        "\n",
        "        # Regularity detection\n",
        "        regularity_score = 0\n",
        "        if len(time_intervals) > 1:\n",
        "            interval_std = time_intervals.std()\n",
        "            interval_mean = time_intervals.mean()\n",
        "            regularity_score = max(0, 1 - (interval_std / max(interval_mean, 1)))\n",
        "\n",
        "        return {\n",
        "            'amount_variability': min(1, amount_cv),\n",
        "            'round_number_ratio': round_ratio,\n",
        "            'transaction_regularity': regularity_score,\n",
        "            'bot_like_score': (round_ratio * 0.4 + regularity_score * 0.6) if regularity_score > 0.8 else 0\n",
        "        }\n",
        "\n",
        "    def _calculate_avg_time_between_txns(self, wallet_data: pd.DataFrame) -> float:\n",
        "        \"\"\"Calculate average time between transactions in days\"\"\"\n",
        "        if len(wallet_data) < 2:\n",
        "            return 0\n",
        "\n",
        "        time_diffs = wallet_data['timestamp'].diff().dropna()\n",
        "        avg_diff = time_diffs.mean()\n",
        "        return avg_diff.total_seconds() / 86400  # Convert to days\n",
        "\n",
        "    def calculate_component_scores(self, features_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Calculate component scores for each wallet\"\"\"\n",
        "        scores_df = features_df.copy()\n",
        "\n",
        "        # Reliability Score (0-1)\n",
        "        scores_df['reliability_score'] = self._calculate_reliability_score(features_df)\n",
        "\n",
        "        # Utilization Score (0-1)\n",
        "        scores_df['utilization_score'] = self._calculate_utilization_score(features_df)\n",
        "\n",
        "        # Longevity Score (0-1)\n",
        "        scores_df['longevity_score'] = self._calculate_longevity_score(features_df)\n",
        "\n",
        "        # Diversity Score (0-1)\n",
        "        scores_df['diversity_score'] = self._calculate_diversity_score(features_df)\n",
        "\n",
        "        # Liquidation Risk Score (0-1, inverted)\n",
        "        scores_df['liquidation_risk_score'] = self._calculate_liquidation_risk_score(features_df)\n",
        "\n",
        "        # Bot Behavior Score (0-1, inverted)\n",
        "        scores_df['bot_behavior_score'] = self._calculate_bot_behavior_score(features_df)\n",
        "\n",
        "        # Volume Consistency Score (0-1)\n",
        "        scores_df['volume_consistency_score'] = self._calculate_volume_consistency_score(features_df)\n",
        "\n",
        "        return scores_df\n",
        "\n",
        "    def _calculate_reliability_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate reliability score based on repayment behavior and consistency\"\"\"\n",
        "        # Repayment behavior (40%)\n",
        "        repayment_component = np.clip(df['repayment_ratio'], 0, 1) * 0.4\n",
        "\n",
        "        # Frequency consistency (30%)\n",
        "        frequency_component = df['frequency_consistency'].fillna(0) * 0.3\n",
        "\n",
        "        # Transaction regularity (30%)\n",
        "        regularity_component = (1 - np.clip(df['avg_days_between_transactions'] / 30, 0, 1)) * 0.3\n",
        "\n",
        "        return repayment_component + frequency_component + regularity_component\n",
        "\n",
        "    def _calculate_utilization_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate utilization score based on healthy borrowing patterns\"\"\"\n",
        "        return df['healthy_utilization_score'].fillna(0.5)\n",
        "\n",
        "    def _calculate_longevity_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate longevity score based on account age and activity\"\"\"\n",
        "        # Account age component\n",
        "        age_score = np.clip(df['account_age_days'] / 365, 0, 1) * 0.6\n",
        "\n",
        "        # Transaction frequency component\n",
        "        freq_score = np.clip(df['transactions_per_day'], 0, 5) / 5 * 0.4\n",
        "\n",
        "        return age_score + freq_score\n",
        "\n",
        "    def _calculate_diversity_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate diversity score based on asset and action variety\"\"\"\n",
        "        return (df['asset_diversity_score'].fillna(0) * 0.6 +\n",
        "                df['action_diversity_score'].fillna(0) * 0.4)\n",
        "\n",
        "    def _calculate_liquidation_risk_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate liquidation risk score (inverted - lower risk = higher score)\"\"\"\n",
        "        # Invert risk score so higher is better\n",
        "        risk_component = 1 - df['risk_score'].fillna(0)\n",
        "        liquidation_penalty = 1 - (df['liquidation_count'] * 0.2)\n",
        "\n",
        "        return np.clip(risk_component * liquidation_penalty, 0, 1)\n",
        "\n",
        "    def _calculate_bot_behavior_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate bot behavior score (inverted - less bot-like = higher score)\"\"\"\n",
        "        return 1 - df['bot_like_score'].fillna(0)\n",
        "\n",
        "    def _calculate_volume_consistency_score(self, df: pd.DataFrame) -> pd.Series:\n",
        "        \"\"\"Calculate volume consistency score\"\"\"\n",
        "        # Moderate variability is good, too low or too high suggests issues\n",
        "        variability = df['amount_variability'].fillna(1)\n",
        "        optimal_variability = 0.3\n",
        "\n",
        "        deviation = np.abs(variability - optimal_variability)\n",
        "        return np.clip(1 - deviation * 2, 0, 1)\n",
        "\n",
        "    def calculate_final_credit_scores(self, scores_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Calculate final credit scores (0-1000) using weighted components\"\"\"\n",
        "        final_scores = scores_df.copy()\n",
        "\n",
        "        # Calculate weighted score\n",
        "        weighted_score = 0\n",
        "        for component, weight in self.feature_weights.items():\n",
        "            if component in scores_df.columns:\n",
        "                weighted_score += scores_df[component] * weight\n",
        "\n",
        "        # Convert to 0-1000 scale\n",
        "        final_scores['credit_score'] = np.clip(weighted_score * 1000, 0, 1000)\n",
        "\n",
        "        # Add score categories\n",
        "        final_scores['score_category'] = final_scores['credit_score'].apply(self._categorize_score)\n",
        "\n",
        "        return final_scores\n",
        "\n",
        "    def _categorize_score(self, score: float) -> str:\n",
        "        \"\"\"Categorize credit score into risk levels\"\"\"\n",
        "        if score >= 800:\n",
        "            return \"Excellent (Low Risk)\"\n",
        "        elif score >= 700:\n",
        "            return \"Good (Moderate Risk)\"\n",
        "        elif score >= 600:\n",
        "            return \"Fair (Elevated Risk)\"\n",
        "        elif score >= 500:\n",
        "            return \"Poor (High Risk)\"\n",
        "        else:\n",
        "            return \"Very Poor (Very High Risk)\"\n",
        "\n",
        "    def generate_score_report(self, scores_df: pd.DataFrame) -> Dict:\n",
        "        \"\"\"Generate a comprehensive scoring report\"\"\"\n",
        "        report = {\n",
        "            'total_wallets': len(scores_df),\n",
        "            'average_score': scores_df['credit_score'].mean(),\n",
        "            'score_distribution': scores_df['score_category'].value_counts().to_dict(),\n",
        "            'component_averages': {},\n",
        "            'top_wallets': scores_df.nlargest(5, 'credit_score')[['wallet', 'credit_score', 'score_category']].to_dict('records'),\n",
        "            'bottom_wallets': scores_df.nsmallest(5, 'credit_score')[['wallet', 'credit_score', 'score_category']].to_dict('records')\n",
        "        }\n",
        "\n",
        "        # Component averages\n",
        "        for component in self.feature_weights.keys():\n",
        "            if component in scores_df.columns:\n",
        "                report['component_averages'][component] = scores_df[component].mean()\n",
        "\n",
        "        return report\n",
        "\n",
        "    def score_wallets(self, json_file_path: str, output_file: str = None) -> Tuple[pd.DataFrame, Dict]:\n",
        "        \"\"\"Main function to score wallets from JSON file\"\"\"\n",
        "        print(\"Loading transaction data...\")\n",
        "        df = self.load_data(json_file_path)\n",
        "\n",
        "        print(f\"Loaded {len(df)} transactions for {df['wallet'].nunique()} unique wallets\")\n",
        "\n",
        "        print(\"Engineering features...\")\n",
        "        features_df = self.engineer_features(df)\n",
        "\n",
        "        print(\"Calculating component scores...\")\n",
        "        scores_df = self.calculate_component_scores(features_df)\n",
        "\n",
        "        print(\"Calculating final credit scores...\")\n",
        "        final_scores_df = self.calculate_final_credit_scores(scores_df)\n",
        "\n",
        "        print(\"Generating report...\")\n",
        "        report = self.generate_score_report(final_scores_df)\n",
        "\n",
        "        # Save results if output file specified\n",
        "        if output_file:\n",
        "            final_scores_df.to_csv(output_file, index=False)\n",
        "            print(f\"Results saved to {output_file}\")\n",
        "\n",
        "        return final_scores_df, report\n",
        "\n",
        "def main():\n",
        "    \"\"\"Example usage\"\"\"\n",
        "    # Initialize scorer\n",
        "    scorer = DeFiCreditScorer()\n",
        "\n",
        "    # Score wallets from user-wallet-transactions.json\n",
        "    try:\n",
        "        results_df, report = scorer.score_wallets('user-wallet-transactions.json', 'wallet_credit_scores.csv')\n",
        "\n",
        "        # Display summary\n",
        "        print(\"\\n=== CREDIT SCORING REPORT ===\")\n",
        "        print(f\"Total Wallets Analyzed: {report['total_wallets']}\")\n",
        "        print(f\"Average Credit Score: {report['average_score']:.1f}\")\n",
        "\n",
        "        print(\"\\nScore Distribution:\")\n",
        "        for category, count in report['score_distribution'].items():\n",
        "            print(f\"  {category}: {count} wallets\")\n",
        "\n",
        "        print(\"\\nComponent Score Averages:\")\n",
        "        for component, avg_score in report['component_averages'].items():\n",
        "            print(f\"  {component}: {avg_score:.3f}\")\n",
        "\n",
        "        print(\"\\nTop 5 Wallets:\")\n",
        "        for wallet_info in report['top_wallets']:\n",
        "            print(f\"  {wallet_info['wallet']}: {wallet_info['credit_score']:.1f} ({wallet_info['score_category']})\")\n",
        "\n",
        "        print(\"\\nBottom 5 Wallets:\")\n",
        "        for wallet_info in report['bottom_wallets']:\n",
        "            print(f\"  {wallet_info['wallet']}: {wallet_info['credit_score']:.1f} ({wallet_info['score_category']})\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: Please ensure 'user-wallet-transactions.json' exists in the current directory\")\n",
        "        print(\"The file should contain transaction data with fields: wallet, action, asset, amount, timestamp\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}